{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model... \n",
      "\n",
      "The boudning box details are organized as follow: \n",
      "\n",
      "[ymin   xmin   ymax   xmax   confidence    class-label] \n",
      "\n",
      "[144, 95, 239, 909, 74, 3]\n",
      "[309, 172, 341, 836, 49, 3]\n",
      "[142, 95, 290, 908, 36, 3]\n",
      "[535, 439, 567, 570, 32, 3]\n",
      "Printing Coordinates\n",
      "0.09469613432884216 0.19171187281608582 0.902506947517395 0.3170095384120941\n",
      "Printing Coordinates\n",
      "0.17143791913986206 0.4096057415008545 0.8303453326225281 0.4513340890407562\n",
      "Printing Coordinates\n",
      "0.09486502408981323 0.1891370266675949 0.9016731977462769 0.38366973400115967\n",
      "Printing Coordinates\n",
      "0.43557509779930115 0.7089440226554871 0.565584123134613 0.7513038516044617\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "import time\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import cv2\n",
    "\n",
    "PATH_TO_MODEL_DIR = \"/home/fesiib/doc2slide/models/fitvid\"\n",
    "PATH_TO_CFG = PATH_TO_MODEL_DIR + \"/centernet_hourglass104_512x512_coco17_tpu-8_document_for_sharing_finetuning.config\"\n",
    "PATH_TO_CKPT = PATH_TO_MODEL_DIR + \"/\"  \n",
    "PATH_TO_LABELS = \"/home/fesiib/doc2slide/dev/Doc2Slide-DL/fitvid/document_label_map.pbtxt\"\n",
    "\n",
    "print('Loading model... ', end='')\n",
    "start_time = time.time()\n",
    "\n",
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(PATH_TO_CFG)\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(PATH_TO_CKPT, 'ckpt-141')).expect_partial()\n",
    "\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    \"\"\"Detect objects in image.\"\"\"\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "    return detections\n",
    "\n",
    "def load_image_into_numpy_array(path):\n",
    "    return np.array(Image.open(path))\n",
    "              \n",
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,use_display_name=True)\n",
    "#image_path = \"/hdd/jykim_archive/huge_OD/temp_move/ver123/video5_2_9_shot5.jpg\"\n",
    "image_path = \"/home/fesiib/doc2slide/dataset_doc2ppt/103/0.jpg\"\n",
    "image_np = load_image_into_numpy_array(image_path)\n",
    "\n",
    "# display the original image\n",
    "ori_image = cv2.imread(image_path)\n",
    "img_height, img_width, _ = ori_image.shape\n",
    "#cv2.imshow(\"ori_image\",ori_image)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# Things to try:\n",
    "# Flip horizontally\n",
    "#image_np = np.fliplr(image_np).copy()\n",
    "# Convert image to grayscale\n",
    "#image_np = np.tile(np.mean(image_np, 2, keepdims=True), (1, 1, 3)).astype(np.uint8)\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "\n",
    "        \n",
    "        \n",
    "for key, value in detections.items()}\n",
    "\n",
    "#print(num_detections)\n",
    "\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "\n",
    "boxes = detections['detection_boxes']\n",
    "width, height = image_np.shape[:2]\n",
    "\n",
    "box = np.squeeze(boxes)\n",
    "scores = detections['detection_scores']\n",
    "\n",
    "classes_pred = detections['detection_classes']\n",
    "\n",
    "min_score_thresh = 0.30\n",
    "\n",
    "bboxes = boxes[scores > min_score_thresh]\n",
    "scores_new = scores[scores > min_score_thresh]\n",
    "classes_pred_new = classes_pred[scores > min_score_thresh]\n",
    "\n",
    "width, height = image_np.shape[:2]\n",
    "final_box = []\n",
    "print('\\n')\n",
    "\n",
    "print('The boudning box details are organized as follow: \\n')\n",
    "print('[ymin   xmin   ymax   xmax   confidence    class-label] \\n')\n",
    "i = 0 \n",
    "for box in bboxes:\n",
    "    ymin, xmin, ymax, xmax = box\n",
    "    final_box = [int(ymin * width), int(xmin * height), int(ymax * width), int(xmax *height) , round(scores_new[i] * 100) , classes_pred_new[i] + 1 ]\n",
    "    i += 1\n",
    "    print(final_box)\n",
    "\n",
    "# for i in range(len(boxes)):\n",
    "        \n",
    "#     ymin = int((box[i,0]*height))\n",
    "#     xmin = int((box[i,1]*width))\n",
    "#     ymax = int((box[i,2]*height))\n",
    "#     xmax = int((box[i,3]*width))\n",
    "\n",
    "#     print(xmin, xmax, ymin , ymax)\n",
    "\n",
    "# Result = np.array(img_np[ymin:ymax,xmin:xmax])\n",
    "\n",
    "\n",
    "#print(\"Detections:\", detections)\n",
    "            # detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "# print(\"Detections_2:\", detections['detection_boxes'])\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(image_np_with_detections, detections['detection_boxes'],\n",
    "                                            detections['detection_classes']+label_id_offset,\n",
    "                                                        detections['detection_scores'],\n",
    "                                                                    category_index,\n",
    "                                                                                use_normalized_coordinates=True,\n",
    "                                                                                            max_boxes_to_draw=200,\n",
    "                                                                                                        min_score_thresh=.30,\n",
    "                                                                                                                    agnostic_mode=False)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[535, 439, 567, 570, 32, 3]\n"
     ]
    }
   ],
   "source": [
    "print (final_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6967000377af96857ff28b0cebd4dca0d384080ddb0e4e318f0b933eeb558ef0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
